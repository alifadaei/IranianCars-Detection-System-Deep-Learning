{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final NN course CNN project with resnet (part 2)\n",
    "\n",
    "üßë‚Äçüéì students :\n",
    "\n",
    "- Ali Fadaeimanesh (40311422011)\n",
    "- Ali Ebadi (40311422016)\n",
    "- Fatemeh Tahaei (40211403004)\n",
    "- Armin Ahangar (40311422014)\n",
    "- Farbod SeyedAli ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.3.6)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /teamspace/studios/this_studio/.cache/kagglehub/datasets/usefashrfi/iran-used-cars-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"usefashrfi/iran-used-cars-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 13\n",
      "Training samples: 6809\n",
      "Validation samples: 1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 0.7574 Acc: 0.7547\n",
      "val Loss: 0.6944 Acc: 0.7889\n",
      "\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8853\n",
      "val Loss: 0.3740 Acc: 0.8851\n",
      "\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 0.2383 Acc: 0.9248\n",
      "val Loss: 0.2768 Acc: 0.9257\n",
      "\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9366\n",
      "val Loss: 0.4056 Acc: 0.8755\n",
      "\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 0.1882 Acc: 0.9430\n",
      "val Loss: 0.2292 Acc: 0.9264\n",
      "\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9529\n",
      "val Loss: 0.2180 Acc: 0.9312\n",
      "\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9648\n",
      "val Loss: 0.2735 Acc: 0.9154\n",
      "\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 0.0453 Acc: 0.9865\n",
      "val Loss: 0.0937 Acc: 0.9759\n",
      "\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 0.0285 Acc: 0.9918\n",
      "val Loss: 0.0824 Acc: 0.9787\n",
      "\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 0.0162 Acc: 0.9954\n",
      "val Loss: 0.0770 Acc: 0.9773\n",
      "\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 0.0147 Acc: 0.9969\n",
      "val Loss: 0.0800 Acc: 0.9794\n",
      "\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 0.0107 Acc: 0.9978\n",
      "val Loss: 0.0782 Acc: 0.9787\n",
      "\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 0.9985\n",
      "val Loss: 0.0817 Acc: 0.9787\n",
      "\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 0.0083 Acc: 0.9988\n",
      "val Loss: 0.0722 Acc: 0.9814\n",
      "\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 0.0077 Acc: 0.9984\n",
      "val Loss: 0.0711 Acc: 0.9835\n",
      "\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.0075 Acc: 0.9984\n",
      "val Loss: 0.0742 Acc: 0.9828\n",
      "\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.0068 Acc: 0.9987\n",
      "val Loss: 0.0728 Acc: 0.9828\n",
      "\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.0057 Acc: 0.9991\n",
      "val Loss: 0.0735 Acc: 0.9835\n",
      "\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.0061 Acc: 0.9988\n",
      "val Loss: 0.0739 Acc: 0.9814\n",
      "\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9990\n",
      "val Loss: 0.0709 Acc: 0.9821\n",
      "\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 0.9988\n",
      "val Loss: 0.0734 Acc: 0.9828\n",
      "\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9994\n",
      "val Loss: 0.0736 Acc: 0.9828\n",
      "\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 0.9994\n",
      "val Loss: 0.0772 Acc: 0.9814\n",
      "\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.0060 Acc: 0.9990\n",
      "val Loss: 0.0749 Acc: 0.9814\n",
      "\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.0033 Acc: 0.9996\n",
      "val Loss: 0.0749 Acc: 0.9807\n",
      "\n",
      "Training complete in 9m 10s\n",
      "Best val Acc: 0.9835\n",
      "Model saved to best_resnet_model.pth\n",
      "Validation Accuracy: 0.9807\n",
      "Test Accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# initial settings\n",
    "BASE_DIR = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/usefashrfi/iran-used-cars-dataset/versions/1/iran-used-cars-dataset/\"\n",
    "SPLIT_DIR = os.path.join(BASE_DIR, \"split\")\n",
    "TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(SPLIT_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(SPLIT_DIR, \"test\")  # ÿØÿ± ÿµŸàÿ±ÿ™ ŸÜ€åÿßÿ≤\n",
    "\n",
    "# check gpu access\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# data transform settings\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                [\n",
    "                    0.485,\n",
    "                    0.456,\n",
    "                    0.406,\n",
    "                ],  # ŸÖŸÇÿßÿØ€åÿ± ŸÜÿ±ŸÖÿßŸÑ‚Äåÿ≥ÿßÿ≤€å ÿßÿ≥ÿ™ÿßŸÜÿØÿßÿ±ÿØ ÿ®ÿ±ÿß€å ŸÖÿØŸÑ‚ÄåŸáÿß€å Ÿæ€åÿ¥‚Äåÿ¢ŸÖŸàÿ≤ÿ¥‚ÄåÿØ€åÿØŸá\n",
    "                [0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": transforms.Compose(\n",
    "        [  # ÿØÿ± ÿµŸàÿ±ÿ™ ŸÜ€åÿßÿ≤\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "#  checking for dirs existance\n",
    "for directory in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"Warning: Directory {directory} does not exist.\")\n",
    "\n",
    "# loading data using imagefolder\n",
    "image_datasets = {\n",
    "    \"train\": datasets.ImageFolder(TRAIN_DIR, transform=data_transforms[\"train\"]),\n",
    "    \"val\": datasets.ImageFolder(VAL_DIR, transform=data_transforms[\"val\"]),\n",
    "    \"test\": datasets.ImageFolder(TEST_DIR, transform=data_transforms[\"test\"]),\n",
    "}\n",
    "\n",
    "# dataloader setup\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(\n",
    "        image_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    ),\n",
    "    \"val\": DataLoader(\n",
    "        image_datasets[\"val\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    ),\n",
    "    \"test\": DataLoader(\n",
    "        image_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    ),  # ÿØÿ± ÿµŸàÿ±ÿ™ ŸÜ€åÿßÿ≤\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {dataset_sizes['train']}\")\n",
    "print(f\"Validation samples: {dataset_sizes['val']}\")\n",
    "\n",
    "# resnet model define\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# configure the output layer sizes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# error function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# learning plan\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "# train and evaluation\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch consists of training and validation phases\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set the model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over the data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass only in training phase\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimization only in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save the best model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "\n",
    "    # Load the best weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 25\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"best_resnet_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Load model from file\n",
    "# MODEL_PATH = './best_resnet_model.pth'\n",
    "# model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# print(\"Model successfully loaded.\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[\"val\"]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_acc = running_corrects.double() / dataset_sizes[\"val\"]\n",
    "    print(f\"Validation Accuracy: {total_acc:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_model(model, dataloaders[\"val\"], device)\n",
    "\n",
    "\n",
    "# (Optional) Evaluation on the test set\n",
    "def evaluate_test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    dataset_size = len(dataloader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[\"test\"]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    total_acc = running_corrects.double() / dataset_size\n",
    "    print(f\"Test Accuracy: {total_acc:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_test(model, dataloaders[\"test\"], device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
